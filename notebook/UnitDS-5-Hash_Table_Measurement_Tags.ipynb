{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Tables\n",
    "\n",
    "The exampleï¼šMeasurement Tags of vapor-compression refrigeration cycle\n",
    "\n",
    "\n",
    "\n",
    "## 1 Measurement Tags of VCC\n",
    "The table store the Measurement Tags of VCC,every the Tag recored has the uniqe tagID\n",
    "\n",
    "Refrigerant 134a is the working fluid in an ideal vapor-compression refrigeration cycle that\n",
    "communicates thermally with a cold region at 0Â°C and a warm region at 26Â°C. \n",
    "\n",
    "Saturated vapor enters the compressor at 0Â°C and saturated liquid leaves the condenser at 26Â°C.\n",
    "\n",
    "The mass flow rate of the refrigerant is 0.08 kg/s.\n",
    "\n",
    "\n",
    "\n",
    "![](./img/vcr/ivcr-ts.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./data/VCC1_Tag.csv\n"
     ]
    }
   ],
   "source": [
    "%%file ./data/VCC1_Tag.csv\n",
    "TagID,Tag,Desc,Unit,Value\n",
    "108600,CompressorIPortM,å‹ç¼©æœºå…¥å£æµé‡,kg/s,0.08\n",
    "108616,CompressorOPortP,å‹ç¼©æœºå‡ºå£å‹åŠ›,MPa,0.6854\n",
    "108613,CompressorOPortT,å‹ç¼©æœºå‡ºå£æ¸©åº¦,Â°C,29.27\n",
    "108714,CondenserOPortT,å†·å‡å™¨å‡ºå£æ¸©åº¦,Â°C,26\n",
    "108708,CondenserOPortX,å†·å‡å™¨å‡ºå£å¹²åº¦,-,0\n",
    "108814,ExpansionValveOPortT,è†¨èƒ€é˜€å‡ºå£æ¸©åº¦,Â°C,26\n",
    "108808,ExpansionValveOPortX,è†¨èƒ€é˜€å‡ºå£å¹²åº¦,Â°C,0\n",
    "108914,EvaporatorValveOPortT,è’¸å‘å™¨å‡ºå£æ¸©åº¦,Â°C,0\n",
    "108908,EvaporatorValveOPortX,è’¸å‘å™¨å‡ºå£å¹²åº¦,-,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Stucture of Tags**\n",
    "\n",
    "```python\n",
    "\n",
    "tag=(id,(tag,desc,value))\n",
    "\n",
    "VCC1_TagTable=[]\n",
    "\n",
    "VCC1_TagTable=[(id,(tag,desc,unit,value)),...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  csv\n",
    "filename=\"./data/VCC1_Tag.csv\"\n",
    "csvfile = open(filename, 'r',encoding=\"utf-8\")\n",
    "csvdata = csv.DictReader(csvfile)\n",
    "VCC1_TagTable=[]\n",
    "for line in csvdata:\n",
    "    id = int(line['TagID']) # convert to int\n",
    "    tag=line['Tag']\n",
    "    desc=line['Desc']\n",
    "    unit=c=line['Unit']\n",
    "    value=float(line['Value'])\n",
    "    VCC1_TagTable.append((id,(tag,desc,unit,value)))\n",
    "csvfile.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108600, ('CompressorIPortM', 'å‹ç¼©æœºå…¥å£æµé‡', 'kg/s', 0.08))\n",
      "(108616, ('CompressorOPortP', 'å‹ç¼©æœºå‡ºå£å‹åŠ›', 'MPa', 0.6854))\n",
      "(108613, ('CompressorOPortT', 'å‹ç¼©æœºå‡ºå£æ¸©åº¦', 'Â°C', 29.27))\n",
      "(108714, ('CondenserOPortT', 'å†·å‡å™¨å‡ºå£æ¸©åº¦', 'Â°C', 26.0))\n",
      "(108708, ('CondenserOPortX', 'å†·å‡å™¨å‡ºå£å¹²åº¦', '-', 0.0))\n",
      "(108814, ('ExpansionValveOPortT', 'è†¨èƒ€é˜€å‡ºå£æ¸©åº¦', 'Â°C', 26.0))\n",
      "(108808, ('ExpansionValveOPortX', 'è†¨èƒ€é˜€å‡ºå£å¹²åº¦', 'Â°C', 0.0))\n",
      "(108914, ('EvaporatorValveOPortT', 'è’¸å‘å™¨å‡ºå£æ¸©åº¦', 'Â°C', 0.0))\n",
      "(108908, ('EvaporatorValveOPortX', 'è’¸å‘å™¨å‡ºå£å¹²åº¦', '-', 1.0))\n"
     ]
    }
   ],
   "source": [
    "for item in  VCC1_TagTable:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the tags of Compressor through tagID by the Linear Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CompressorIPortM', 'å‹ç¼©æœºå…¥å£æµé‡', 'kg/s', 0.08)\n",
      "('CompressorOPortP', 'å‹ç¼©æœºå‡ºå£å‹åŠ›', 'MPa', 0.6854)\n",
      "('EvaporatorValveOPortT', 'è’¸å‘å™¨å‡ºå£æ¸©åº¦', 'Â°C', 0.0)\n",
      "('EvaporatorValveOPortX', 'è’¸å‘å™¨å‡ºå£å¹²åº¦', '-', 1.0)\n"
     ]
    }
   ],
   "source": [
    "CompressorTagIDList=[108600,108616,108614,108914,108908]\n",
    "for tagid in CompressorTagIDList:\n",
    "    for item in VCC1_TagTable:\n",
    "        if tagid==item[0]:\n",
    "            print(item[1])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linear Search will perform  $ğ‘‚(N)$  \n",
    "\n",
    "If we put merge sort together with binary search, we have a nice way to search lists. We use merge sort to preprocess the list in order $ğ‘‚(n*log(n))$ time, and then we use binary search to test whether elements are in the list in order $ğ‘‚(log(n))$ time. If we search the list k times, the overall time complexity is order $ğ‘‚(n*log(n) + k*log(n))$\n",
    "\n",
    "This is good, but we can still **ask**, `is logarithmic the best` that we can do for search when we are willing to do some preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we introduced the type <font color=\"blue\">dict</font> dictionaries use a technique called <b>hashing</b> to do <b>the lookup in time</b> \n",
    "\n",
    "* that is nearly `independent` of the `size` of the dictionary\n",
    "\n",
    "The basic idea behind hashing is\n",
    "\n",
    "* **convert the key to an integer, and then use that integer to index into a list**\n",
    "\n",
    "which can be done in `constant` time. \n",
    "\n",
    "**Hash functions** : any function that can be used to map data of `arbitrary` size to `fixed-size` values.\n",
    "\n",
    "* `CurTagID%ListSize`(é™¤ç•™ä½™æ•°æ³• k mod m - å…³é”®å­—ké™¤ä»¥è¡¨é•¿åº¦mçš„ä½™æ•°)\n",
    "![](./img/ds/hash1.png)\n",
    "\n",
    "**Hash value** : The values returned by a hash function are called \n",
    "    \n",
    "* `Index_TagID=CurTagID%ListSize`\n",
    "\n",
    "**Hash table**: the data structure that maps keys to values with hashing\n",
    "\n",
    "* `VCC1_TagTable=[None for i in range(ListSize)]`\n",
    "\n",
    ">æ•£åˆ—è¡¨é€šè¿‡æŠŠå…³é”®ç å€¼æ˜ å°„åˆ°è¡¨ä¸­ä¸€ä¸ªä½ç½®æ¥è®¿é—®è®°å½•ï¼Œä»¥åŠ å¿«æŸ¥æ‰¾çš„é€Ÿåº¦ã€‚è¿™ä¸ªæ˜ å°„å‡½æ•°å«åšæ•£åˆ—å‡½æ•°ï¼Œå­˜æ”¾è®°å½•çš„æ•°ç»„å«åšæ•£åˆ—è¡¨ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example we use the remainder `key%ListSize` as the index into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108600 0\n",
      "108616 16\n",
      "108613 13\n",
      "108714 24\n",
      "108708 18\n",
      "108814 4\n",
      "108808 28\n",
      "108914 14\n",
      "108908 8\n"
     ]
    }
   ],
   "source": [
    "import  csv\n",
    "filename=\"./data/VCC1_Tag.csv\"\n",
    "csvfile = open(filename, 'r',encoding=\"utf-8\")\n",
    "csvdata = csv.DictReader(csvfile)\n",
    "\n",
    "# set the size of the store list\n",
    "ListSize=30;\n",
    "# the store table \n",
    "VCC1_TagTable=[None for i in range(ListSize)]\n",
    "for line in csvdata:\n",
    "    id = int(line['TagID'])\n",
    "    tag=line['Tag']\n",
    "    desc=line['Desc']\n",
    "    unit=line['Unit']\n",
    "    value=float(line['Value'])\n",
    "    # convert the key to an integer: index of the list\n",
    "    Index_TagID= id%ListSize\n",
    "    # put the record in the index of the list\n",
    "    VCC1_TagTable[Index_TagID]=(id,(tag,desc,unit,value))\n",
    "    print(id, Index_TagID)\n",
    "csvfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (108600, ('CompressorIPortM', 'å‹ç¼©æœºå…¥å£æµé‡', 'kg/s', 0.08))\n",
      "1 None\n",
      "2 None\n",
      "3 None\n",
      "4 (108814, ('ExpansionValveOPortT', 'è†¨èƒ€é˜€å‡ºå£æ¸©åº¦', 'Â°C', 26.0))\n",
      "5 None\n",
      "6 None\n",
      "7 None\n",
      "8 (108908, ('EvaporatorValveOPortX', 'è’¸å‘å™¨å‡ºå£å¹²åº¦', '-', 1.0))\n",
      "9 None\n",
      "10 None\n",
      "11 None\n",
      "12 None\n",
      "13 (108613, ('CompressorOPortT', 'å‹ç¼©æœºå‡ºå£æ¸©åº¦', 'Â°C', 29.27))\n",
      "14 (108914, ('EvaporatorValveOPortT', 'è’¸å‘å™¨å‡ºå£æ¸©åº¦', 'Â°C', 0.0))\n",
      "15 None\n",
      "16 (108616, ('CompressorOPortP', 'å‹ç¼©æœºå‡ºå£å‹åŠ›', 'MPa', 0.6854))\n",
      "17 None\n",
      "18 (108708, ('CondenserOPortX', 'å†·å‡å™¨å‡ºå£å¹²åº¦', '-', 0.0))\n",
      "19 None\n",
      "20 None\n",
      "21 None\n",
      "22 None\n",
      "23 None\n",
      "24 (108714, ('CondenserOPortT', 'å†·å‡å™¨å‡ºå£æ¸©åº¦', 'Â°C', 26.0))\n",
      "25 None\n",
      "26 None\n",
      "27 None\n",
      "28 (108808, ('ExpansionValveOPortX', 'è†¨èƒ€é˜€å‡ºå£å¹²åº¦', 'Â°C', 0.0))\n",
      "29 None\n"
     ]
    }
   ],
   "source": [
    "for  i,item in  enumerate(VCC1_TagTable):\n",
    "    print(i,item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get get one tag info from TagID with the  Index_TagID\n",
    "\n",
    "It is done in **constant** time that is nearly `independent` of the `size` of VCC1_TagList\n",
    "\n",
    "The complexity is $O(1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (108600, ('CompressorIPortM', 'å‹ç¼©æœºå…¥å£æµé‡', 'kg/s', 0.08))\n",
      "16 (108616, ('CompressorOPortP', 'å‹ç¼©æœºå‡ºå£å‹åŠ›', 'MPa', 0.6854))\n",
      "13 (108613, ('CompressorOPortT', 'å‹ç¼©æœºå‡ºå£æ¸©åº¦', 'Â°C', 29.27))\n",
      "14 (108914, ('EvaporatorValveOPortT', 'è’¸å‘å™¨å‡ºå£æ¸©åº¦', 'Â°C', 0.0))\n",
      "8 (108908, ('EvaporatorValveOPortX', 'è’¸å‘å™¨å‡ºå£å¹²åº¦', '-', 1.0))\n"
     ]
    }
   ],
   "source": [
    "CompressorTagIDList=[108600,108616,108613,108914,108908]\n",
    "for tagid in CompressorTagIDList:\n",
    "    Index_TagID=tagid%ListSize\n",
    "    print(Index_TagID,VCC1_TagTable[Index_TagID])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Collision \n",
    "\n",
    "**Collision**: a situation that occurs when two distinct pieces of data have the same hash value\n",
    "\n",
    "* å†²çªï¼šåœ¨æ•£åˆ—è¡¨ä¸­ï¼Œä¸åŒçš„å…³é”®å­—å€¼å¯¹åº”åˆ°åŒä¸€ä¸ªå­˜å‚¨ä½ç½®çš„ç°è±¡\n",
    "\n",
    "\n",
    "For a a hash function. if the space of possible outputs is **smaller** than the space of possible inputs, \n",
    "\n",
    "* a hash function is a `many`-to-`one` mapping. \n",
    "\n",
    "the different keys are mapped to the same hash value,it is called a <b>collision</b>. \n",
    "\n",
    "For example: the simple hash function \n",
    "\n",
    "* `id%ListSize`\n",
    "\n",
    "The hase value of key is the remainder `key%numIndices`\n",
    "\n",
    "**If**\n",
    "\n",
    "* the input sizes of key is :10\n",
    "\n",
    "* the output sizes of hash value:ListSize is 5\n",
    "\n",
    "you may see many Collision!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108600 0\n",
      "108616 1\n",
      "108613 3\n",
      "108714 4\n",
      "108708 3\n",
      "108814 4\n",
      "108808 3\n",
      "108914 4\n",
      "108908 3\n"
     ]
    }
   ],
   "source": [
    "import  csv\n",
    "filename=\"./data/VCC1_Tag.csv\"\n",
    "csvfile = open(filename, 'r',encoding=\"utf-8\")\n",
    "csvdata = csv.DictReader(csvfile)\n",
    "\n",
    "# set the size of the store list\n",
    "ListSize=5;\n",
    "# the store table \n",
    "for line in csvdata:\n",
    "    id = int(line['TagID'])\n",
    "    # convert the key to an integer: index of the list\n",
    "    Index_TagID= id%ListSize\n",
    "    print(id, Index_TagID)\n",
    "csvfile.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If Collision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  csv\n",
    "filename=\"./data/VCC1_Tag.csv\"\n",
    "csvfile = open(filename, 'r',encoding=\"utf-8\")\n",
    "csvdata = csv.DictReader(csvfile)\n",
    "\n",
    "# set the size of the store list\n",
    "ListSize=5;\n",
    "# the store table \n",
    "VCC1_TagTable=[None for i in range(ListSize)]\n",
    "for line in csvdata:\n",
    "    id = int(line['TagID'])\n",
    "    tag=line['Tag']\n",
    "    desc=line['Desc']\n",
    "    unit=line['Unit']\n",
    "    value=float(line['Value'])\n",
    "    # convert the key to an integer: index of the list\n",
    "    Index_TagID= id%ListSize\n",
    "    # put the record in the index of the list\n",
    "    VCC1_TagTable[Index_TagID]=(id,(tag,desc,unit,value))\n",
    "csvfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108600, ('CompressorIPortM', 'å‹ç¼©æœºå…¥å£æµé‡', 'kg/s', 0.08))\n",
      "(108616, ('CompressorOPortP', 'å‹ç¼©æœºå‡ºå£å‹åŠ›', 'MPa', 0.6854))\n",
      "(108908, ('EvaporatorValveOPortX', 'è’¸å‘å™¨å‡ºå£å¹²åº¦', '-', 1.0))\n",
      "(108914, ('EvaporatorValveOPortT', 'è’¸å‘å™¨å‡ºå£æ¸©åº¦', 'Â°C', 0.0))\n",
      "(108908, ('EvaporatorValveOPortX', 'è’¸å‘å™¨å‡ºå£å¹²åº¦', '-', 1.0))\n"
     ]
    }
   ],
   "source": [
    "CompressorTagIDList=[108600,108616,108613,108914,108908]\n",
    "for tagid in CompressorTagIDList:\n",
    "    Index_TagID=tagid%ListSize\n",
    "    print(VCC1_TagTable[Index_TagID]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will see \n",
    "```\n",
    "(108908, ('EvaporatorValveOPortX', 'è’¸å‘å™¨å‡ºå£å¹²åº¦', '-', 1.0))\n",
    "(108908, ('EvaporatorValveOPortX', 'è’¸å‘å™¨å‡ºå£å¹²åº¦', '-', 1.0))\n",
    "```\n",
    "because the Collision \n",
    "```\n",
    "108613 3\n",
    "108708 3\n",
    "108808 3\n",
    "108908 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The paths to handle the collision in Hash Table**\n",
    "\n",
    "1. **minimizes collisions**: A `good hash function` produces : **uniform distribution** every output in the range is equally probable, which `minimizes` the probability of `collisions`(æ•£åˆ—å‡½æ•°è®¾è®¡è¦ç‚¹:å‡åŒ€æ€§å¥½,å‡å°‘å…ƒç´ å†²çªæ¬¡æ•°)\n",
    "\n",
    "2. **collision resolution**: Separate Chainingg(åˆ†ç¦»é“¾æ¥æ³•), Open Addressing(å¼€æ”¾åœ°å€æ³•ï¼‰ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Handle collisions:Separate Chaining(åˆ†ç¦»é“¾æ¥æ³•)\n",
    "\n",
    "There are different ways through which a collision can be resolved. We will look at a method called **Separate Chaining(åˆ†ç¦»é“¾æ¥æ³•)**, \n",
    "\n",
    "* **Chain hashing** avoids collision. The idea is to make each cell of hash table point to a linked list of records that have same hash function value.(å°†æ•£åˆ—åˆ°åŒä¸€ä¸ªå€¼çš„æ‰€æœ‰å…ƒç´ ä¿ç•™åˆ°ä¸€ä¸ªé“¾è¡¨ä¸­)\n",
    "\n",
    "The hash table is a list of `hash buckets`. \n",
    "\n",
    "* **bucket(æ¡¶)**: a list of `key/value` pairs with same hash function value\n",
    "\n",
    "![](./img/ds/Hashcollisionbyseparatechaining.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Hash Table in Python**\n",
    "\n",
    "The basic idea is to represent the hash table by a list where **each item** is a list of **key/value** pairs that have the `same` hash index\n",
    "\n",
    "```python\n",
    "[\n",
    "[bucket for the same hash value1],\n",
    "[bucket for the same hash value2]\n",
    ",...\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "For examples:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyvalues=[(8,\"èµµ\"),(19,\"é’±\"),(28,\"å­™\"),(35,\"æ\"),(17,\"å‘¨\")]\n",
    "num_buckets=8\n",
    "buckets=[[] for i in range(num_buckets)]\n",
    "\n",
    "print(\"Key\",\"The address in buckets\",\"\\n\"+20*\"-\")\n",
    "for item in keyvalues:\n",
    "    #hash function: key % num_buckets\n",
    "    address= item[0] % num_buckets\n",
    "    buckets[address].append(item)\n",
    "    print(item[0],address)\n",
    "\n",
    "print(\"\\nNo.\",\"Bucket\",\"\\n\"+20*\"-\")   \n",
    "for  i,bucket in  enumerate(buckets):\n",
    "    print(i,bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=35\n",
    "hashvalue=key % num_buckets\n",
    "for item in buckets[hashvalue]:\n",
    "    if item[0]==key:\n",
    "        print(key,item[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 The Class of Separate Chaining\n",
    "\n",
    "\n",
    "#### 3.1.1  Init the hash table\n",
    "\n",
    "```python\n",
    "def __init__(self, numBuckets):\n",
    "   \"\"\"\n",
    "   The instance variable buckets is initialized to a list of numBuckets empty lists\n",
    "   \"\"\"\n",
    "\n",
    "        self.buckets = []\n",
    "        self.numBuckets = numBuckets\n",
    "        for i in range(numBuckets):\n",
    "            self.buckets.append([]) \n",
    "```\n",
    "\n",
    "#### 3.1.2  hash function\n",
    "\n",
    "```python\n",
    " def getHashValue(self, dictKey):\n",
    "        return dictKey%self.numBuckets\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.1.3 addEntry\n",
    "\n",
    "By making each bucket a list, we handle collisions by storing all of the values that hash to the same bucket in the list</b>. \n",
    "\n",
    "```python\n",
    "def addEntry(self, dictKey, dictVal):\n",
    "    \"\"\"\n",
    "     To store or look up an entry with key **dictKey\n",
    "    \"\"\" \n",
    "    hashBucket = self.buckets[self.getHashValue(dictKey)] # hashing the location `hashBucket` list in  the list of self.buckets \n",
    "    for i in range(len(hashBucket)):\n",
    "        if hashBucket[i][0] == dictKey:# the item in each bucket is tuple: (dictKey, dictVal)\n",
    "            hashBucket[i] = (dictKey, dictVal) #if one was found,replace\n",
    "            return\n",
    "         hashBucket.append((dictKey, dictVal)) # append a new entry (dictKey, dictVal) to the bucket if none was found.\n",
    "```      \n",
    "   \n",
    "we use the hash function `i%j` to convert dictKey into an integer, \n",
    "```python  \n",
    "    hashBucket = self.buckets[dictKey%self.numBuckets]\n",
    "```    \n",
    "and use that integer to index into buckets \n",
    "```python\n",
    "   hashBucket[i]\n",
    "```\n",
    "to find the hash bucket associated with **dictKey**: if <b>a value is to be stored</b>,then  \n",
    "\n",
    "* if one was found:  <b>replace</b> the value in the existing entry,  \n",
    "\n",
    "* if none was found: <b>append</b> a new entry to the bucket\n",
    "\n",
    "\n",
    "#### 3.1.4 getValue\n",
    "\n",
    "```python \n",
    "\n",
    "def getValue(self, dictKey)\n",
    "```\n",
    "We then search that bucket (which is a list) linearly to see if there is an entry with the key dictKey.\n",
    "\n",
    "```python \n",
    " for e in hashBucket:\n",
    "            if e[0] == dictKey: // key\n",
    "                return e[1]     // value\n",
    "```\n",
    "\n",
    "If we are doing <b>a lookup</b> and there is an entry with the key, we simply return the value stored with that key. \n",
    "\n",
    "If there is no entry with that key, we return None. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class intDict(object):\n",
    "    \"\"\"A dictionary with integer keys\"\"\"\n",
    "    \n",
    "    def __init__(self, numBuckets):\n",
    "        \"\"\"Create an empty dictionary\n",
    "           buckets is initialized to a list of numBuckets empty lists.\n",
    "        \"\"\"\n",
    "        self.buckets = []\n",
    "        self.numBuckets = numBuckets\n",
    "        for i in range(numBuckets):\n",
    "            self.buckets.append([]) # empty list\n",
    "            \n",
    "    def getHashValue(self, dictKey):\n",
    "        return dictKey%self.numBuckets\n",
    "    \n",
    "    def addEntry(self, dictKey, dictVal):\n",
    "        \"\"\"Assumes dictKey an int.  Adds an entry.\"\"\"\n",
    "        hashBucket = self.buckets[self.getHashValue(dictKey)]\n",
    "        for i in range(len(hashBucket)):\n",
    "            if hashBucket[i][0] == dictKey:\n",
    "                hashBucket[i] = (dictKey, dictVal) #if one was found,replace\n",
    "                return\n",
    "        hashBucket.append((dictKey, dictVal)) # append a new entry to the bucket if none was found.\n",
    "        \n",
    "    def getValue(self, dictKey):\n",
    "        \"\"\"Assumes dictKey an int.  Returns entry associated\n",
    "           with the key dictKey\"\"\"\n",
    "        hashBucket = self.buckets[self.getHashValue(dictKey)]\n",
    "        for e in hashBucket:\n",
    "            if e[0] == dictKey: # key\n",
    "                return e[1]     # value \n",
    "        return None\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = '{'\n",
    "        for b in self.buckets:\n",
    "            for e in b:\n",
    "                result = result + str(e[0]) + ':' + str(e[1]) + ','\n",
    "        return result[:-1] + '}' #result[:-1] omits the last comma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Example: Measurement Tags of VCC\n",
    "\n",
    "The following code constructs an **intDict** with TagID of VCC. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  csv\n",
    "filename=\"./data/VCC1_Tag.csv\"\n",
    "csvfile = open(filename, 'r',encoding=\"utf-8\")\n",
    "csvdata = csv.DictReader(csvfile)\n",
    "Entrys=[]\n",
    "for line in csvdata:\n",
    "    id = int(line['TagID'])\n",
    "    tag=line['Tag']\n",
    "    desc=line['Desc']\n",
    "    unit=line['Unit']\n",
    "    value=float(line['Value'])\n",
    "    Entrys.append((id,(tag,desc,unit,value))) \n",
    "csvfile.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put entrys into <font color=\"blue\">intDict</font>\n",
    "\n",
    "**hash table larger size, none collisions**\n",
    "\n",
    "* numBuckets =29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numBuckets =29\n",
    "# numBuckets 29  >entries 10\n",
    "D = intDict(numBuckets)\n",
    "for item in Entrys:\n",
    "    D.addEntry(item[0],item[1])\n",
    "\n",
    "print('The intDict is:')\n",
    "print(D)\n",
    "\n",
    "print('\\n', 'The hase buckets are:')\n",
    "i=0\n",
    "for hashBucket in D.buckets:\n",
    "    print('BucketID',i,'  ', hashBucket)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that many of the hash buckets are **empty**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompressorTagIDList=[108600,108616,108614,108914,108908]\n",
    "for tag in CompressorTagIDList:\n",
    "    thebucket=D.getValue(tag)   \n",
    "    print(tag,thebucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hash table smaller sise ,collisions**\n",
    "\n",
    "* numBucket=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numBuckets=5\n",
    "# numBuckets 5 <entries 10\n",
    "D = intDict(numBuckets)\n",
    "for item in Entrys:\n",
    "    D.addEntry(item[0],item[1])\n",
    "\n",
    "print('The intDict is:')\n",
    "print(D)\n",
    "\n",
    "print('\\n', 'The hase buckets are:')\n",
    "i=0\n",
    "for hashBucket in D.buckets:\n",
    "    print('BucketID',i,'  ', hashBucket)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**one, two, or three tuples** depending upon <b>the number of collisions</b> that occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompressorTagIDList=[108600,108616,108614,108914,108908]\n",
    "for tagid in CompressorTagIDList:\n",
    "    thebucket=D.getValue(tagid)   \n",
    "    print(tag,thebucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The complexity of **getValue**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there were <b>no collisions</b> it would be <b>O(1)</b>,  \n",
    "\n",
    "* because each hash bucket would be of length 0 or 1.\n",
    "\n",
    "There might be <b>collisions</b>ï¼Œ\n",
    "\n",
    "* If everything hashed to **the same bucket**, it would be <b>O(n)</b> where n is the number of entries in the dictionaryï¼Œbecause the code would perform a linear search on that hash bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagid=108808\n",
    "thebucket=D.getValue(tagid)  \n",
    "print(tagid,thebucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By making the hash table large enough,\n",
    "\n",
    "we can reduce the number of collisions sufficiently to allow us to treat the complexity as O(1).\n",
    "\n",
    "* å¦‚æœå¯ä»¥æä¾›ä¸€ä¸ªè¶³å¤Ÿå¤§çš„æ•°ç»„ï¼Œä¸ºæ¯ä¸ªå…³é”®å­—ä¿ç•™ä¸€ä¸ªä½ç½®ï¼Œå°±å¯ä»¥**ç›´æ¥å¯»å€**æŠ€æœ¯ï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯O(1)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading \n",
    "\n",
    "### 1 Hash: intDict in C\n",
    "\n",
    "* intDict.h/c\n",
    "\n",
    "* mainintDict.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./demo/include/intDict.h\n",
    "#ifndef INTDICTH\n",
    "#define INTDICTH\n",
    "\n",
    "typedef struct _node\n",
    "{\n",
    "\tint key;\n",
    "\tint value;\n",
    "\tstruct _node *next;\n",
    "} Node;\n",
    "\n",
    "typedef struct _hashtable\n",
    "{\n",
    "\tint numBuckets;\n",
    "\tNode **buckets; //the linked list stack\n",
    "} Hashtable;\n",
    "\n",
    "// Create hash table\n",
    "Hashtable *createHash(int numBuckets);\n",
    "\n",
    "// free hash table\n",
    "void *freeHash(Hashtable *hTable);\n",
    "\n",
    "// hash function for int keys\n",
    "int inthash(int key, int numBuckets);\n",
    "\n",
    "// Add Entry to table - keyed by int\n",
    "void addEntry(Hashtable *hTable, int key, int value);\n",
    "\n",
    "// Lookup  by int key\n",
    "Node *searchEntry(Hashtable *hTable, int key);\n",
    "\n",
    "// Get by int key\n",
    "int getValue(Hashtable *hTable, int key);\n",
    "\n",
    "#endif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./demo/src/intDict.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include \"intDict.h\"\n",
    "\n",
    "// Create hash table\n",
    "Hashtable *createHash(int numBuckets)\n",
    "{\n",
    "\tHashtable *table = (Hashtable *)malloc(sizeof(Hashtable *));\n",
    "\tif (!table)\n",
    "\t{\n",
    "\t\treturn NULL;\n",
    "\t}\n",
    "\n",
    "\ttable->buckets = (Node **)malloc(sizeof(Node) * numBuckets);\n",
    "\tif (!table->buckets)\n",
    "\t{\n",
    "\t\tfree(table);\n",
    "\t\treturn NULL;\n",
    "\t}\n",
    "\n",
    "\ttable->numBuckets = numBuckets;\n",
    "\t// initialize the head pointer of the bucket stack to NULL\n",
    "\tfor (int i = 0; i < table->numBuckets; i++)\n",
    "\t\ttable->buckets[i] = NULL;\n",
    "\n",
    "\treturn table;\n",
    "}\n",
    "\n",
    "void *freeHash(Hashtable *hTable)\n",
    "{\n",
    "\tNode *b, *p;\n",
    "\tfor (int i = 0; i < hTable->numBuckets; i++)\n",
    "\t{\n",
    "\t\tb = hTable->buckets[i];\n",
    "\t\twhile (b != NULL)\n",
    "\t\t{\n",
    "\t\t\tp = b->next;\n",
    "\t\t\tfree(b);\n",
    "\t\t\tb = p;\n",
    "\t\t}\n",
    "\t}\n",
    "\tfree(hTable->buckets);\n",
    "\tfree(hTable);\n",
    "}\n",
    "\n",
    "// hash function for int keys\n",
    "int inthash(int key, int numBuckets)\n",
    "{\n",
    "\treturn key % numBuckets;\n",
    "}\n",
    "\n",
    "// Lookup  by int key\n",
    "Node *searchEntry(Hashtable *hTable, int key)\n",
    "{\n",
    "\tNode *p;\n",
    "\tint addr = inthash(key, hTable->numBuckets);\n",
    "\tp = hTable->buckets[addr];\n",
    "\n",
    "\twhile (p && p->key != key)\n",
    "\t\tp = p->next;\n",
    "\n",
    "\treturn p;\n",
    "}\n",
    "\n",
    "// Add Entry to table - keyed by int\n",
    "void addEntry(Hashtable *hTable, int key, int value)\n",
    "{\n",
    "\tint addr;\n",
    "\tNode *p, *entry;\n",
    "\tp = searchEntry(hTable, key);\n",
    "\tif (p)\n",
    "\t{\n",
    "\t\treturn;\n",
    "\t}\n",
    "\telse\n",
    "\t{ /*\n",
    "          add a new item on the top of the linked list stack \n",
    "          and a pointer to the top element.  \n",
    "       */\n",
    "\t\taddr = inthash(key, hTable->numBuckets);\n",
    "\t\tentry = (Node *)malloc(sizeof(Node));\n",
    "\t\tentry->key = key;\n",
    "\t\tentry->value = value;\n",
    "\t\tentry->next = hTable->buckets[addr];\n",
    "\t\thTable->buckets[addr] = entry;\n",
    "\t}\n",
    "}\n",
    "\n",
    "// Get by int\n",
    "int getValue(Hashtable *hTable, int key)\n",
    "{\n",
    "\tNode *p;\n",
    "\tp = searchEntry(hTable, key);\n",
    "\tif (p)\n",
    "\t{\n",
    "\t\treturn p->value;\n",
    "\t}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./demo/src/mainintDict.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include \"intDict.h\"\n",
    "\n",
    "int main()\n",
    "{\n",
    "\tint numBuckets = 5;\n",
    "\tint numEntries = 20;\n",
    "\tHashtable *hTable;\n",
    "\tint *key;\n",
    "\tint *value;\n",
    "\n",
    "\thTable = createHash(numBuckets);\n",
    "\tkey = (int *)malloc(sizeof(int) * numEntries);\n",
    "\tvalue = (int *)malloc(sizeof(int) * numEntries);\n",
    "    \n",
    "\tprintf(\"The value of the intDict is:\\n\");\n",
    "\tprintf(\"(key value)\\n\");\n",
    "    srand(time(NULL));\n",
    "\tfor (int i = 0; i < numEntries; i++)\n",
    "\t{\n",
    "\t\tkey[i] = rand() % 100000;\n",
    "\t\tvalue[i] = i;\n",
    "\n",
    "\t\taddEntry(hTable, key[i], value[i]);\n",
    "\t\tprintf(\"(%d %d)\\n\", key[i], value[i]);\n",
    "\t}\n",
    "\n",
    "\tprintf(\"\\nThe buckets(the linked list stack) are: \\n\");\n",
    "\tfor (int i = 0; i < hTable->numBuckets; i++)\n",
    "\t{\n",
    "\t\tNode *b, *p;\n",
    "\t\tb = hTable->buckets[i];\n",
    "\t\tprintf(\"bucket %d :\", i);\n",
    "\t\tif (b)\n",
    "\t\t{\n",
    "\t\t\tfor (p = b; p != NULL; p = p->next)\n",
    "\t\t\t\tprintf(\" (%d %d) \", p->key, p->value);\n",
    "\t\t\tprintf(\"\\n\");\n",
    "\t\t}\n",
    "\t\telse\n",
    "\t\t\tprintf(\"\\n\");\n",
    "\t}\n",
    "\n",
    "\tprintf(\"\\nHash search(even):\\n\");\n",
    "\tprintf(\"(key value) : key -> value:\\n\");\n",
    "\tfor (int i = 0; i < numEntries; i++)\n",
    "\t{\n",
    "\t\tif (i % 2 == 0)\n",
    "\t\t{\n",
    "\t\t\tint val = getValue(hTable, key[i]);\n",
    "\t\t\tprintf(\"(%d  %d): -> %d \\n\", key[i], value[i], val);\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tfree(key);\n",
    "\tfree(value);\n",
    "\n",
    "\tfreeHash(hTable);\n",
    "\n",
    "\treturn 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -o ./demo/bin/mainintDict ./demo/src/mainintDict.c ./demo/src/intDict.c -I./demo/include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!.\\demo\\bin\\mainintDict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Unordered Map(C++11)\n",
    "\n",
    "Unordered maps are associative containers that store elements formed by the combination of a key value and a mapped value, and which allows for fast retrieval of individual elements based on their keys.\n",
    "\n",
    "In an unordered_map, the key value is generally used to uniquely identify the element, while the mapped value is an object with the content associated to this key. Types of key and mapped value may differ.\n",
    "\n",
    "Internally, the elements in the unordered_map are not sorted in any particular order with respect to either their key or mapped values, but organized into buckets depending on their hash values to allow for fast access to individual elements directly by their key values (with a constant average time complexity on average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ./demo/src/demo1_unordered_map.cpp\n",
    "\n",
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <tuple>\n",
    "#include <unordered_map>\n",
    " \n",
    "using namespace std;\n",
    "typedef tuple<string,string,string,float> tupTag;\n",
    " \n",
    "int main()\n",
    "{  \n",
    "    unordered_map<int, tupTag> tags;\n",
    "    tags[108600] =(tupTag){\"CompressorIPortM\",\"å‹ç¼©æœºå…¥å£è´¨é‡æµé‡\",\"kg/s\",0.08 };\n",
    "    cout << \"Tag 108600:  \" <<get<0>(tags[108600]) <<\"\\t\"<< get<1>(tags[108600])\n",
    "         << \"\\t\"<<get<2>(tags[108600])<< \"\\t\"<<get<3>(tags[108600])<<endl;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -fexec-charset=GBK -o ./demo/bin/demo1_unordered_map.exe ./demo/src/demo1_unordered_map.cpp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!.\\demo\\bin\\demo1_unordered_map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further Reading\n",
    "\n",
    "* ä¸¥è”šæ•ï¼Œæå†¬æ¢…ï¼Œå´ä¼Ÿæ°‘. æ•°æ®ç»“æ„ï¼ˆCè¯­è¨€ç‰ˆï¼‰ï¼Œäººæ°‘é‚®ç”µå‡ºç‰ˆç¤¾ï¼ˆç¬¬2ç‰ˆï¼‰,2015å¹´2æœˆ  \n",
    "\n",
    "* Mark Allen Weiss. Data Structures and Algorithm Analysis in C\n",
    "\n",
    "* Hash table https://en.wikipedia.org/wiki/Hash_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
